{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/NX-AI/tirex/blob/main/examples/quick_start_tirex.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open Quick Start In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install TiRex package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install 'tirex-ts[notebooks,gluonts,hfdataset]' -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports and Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from tirex import ForecastModel, load_model\n",
        "\n",
        "\n",
        "def plot_forecast(ctx, quantile_fc, real_future_values=None):\n",
        "    median_forecast = quantile_fc[:, 4].numpy()\n",
        "    lower_bound = quantile_fc[:, 0].numpy()\n",
        "    upper_bound = quantile_fc[:, 8].numpy()\n",
        "\n",
        "    original_x = range(len(ctx))\n",
        "    forecast_x = range(len(ctx), len(ctx) + len(median_forecast))\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(original_x, ctx, label=\"Ground Truth Context\", color=\"#4a90d9\")\n",
        "    if real_future_values is not None:\n",
        "        original_fut_x = range(len(ctx), len(ctx) + len(real_future_values))\n",
        "        plt.plot(original_fut_x, real_future_values, label=\"Ground Truth Future\", color=\"#4a90d9\", linestyle=\":\")\n",
        "    plt.plot(forecast_x, median_forecast, label=\"Forecast (Median)\", color=\"#d94e4e\", linestyle=\"--\")\n",
        "    plt.fill_between(\n",
        "        forecast_x, lower_bound, upper_bound, color=\"#d94e4e\", alpha=0.1, label=\"Forecast 10% - 90% Quantiles\"\n",
        "    )\n",
        "    plt.xlim(left=0)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "data_base_url = \"https://raw.githubusercontent.com/NX-AI/tirex/refs/heads/main/tests/data/\"\n",
        "data_short = pd.read_csv(f\"{data_base_url}/air_passengers.csv\").values.reshape(-1)\n",
        "data_long = pd.read_csv(f\"{data_base_url}/loop_seattle_5T.csv\").values.reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model: ForecastModel = load_model(\"NX-AI/TiRex\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate Forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Short Horizon - Example\n",
        "ctx_s, future_s = np.split(data_short, [-12])\n",
        "quantiles, mean = model.forecast(ctx_s, prediction_length=24)\n",
        "plot_forecast(ctx_s, quantiles[0], future_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Long Horizon - Example\n",
        "ctx_l, future_l = np.split(data_long, [-512])\n",
        "quantiles, mean = model.forecast(ctx_l, prediction_length=768)\n",
        "plot_forecast(ctx_l, quantiles[0], future_l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Input Options\n",
        "\n",
        "TiRex supports forecasting with different input types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = torch.tensor(data_short)\n",
        "\n",
        "# Torch tensor (2D or 1D)\n",
        "quantiles, means = model.forecast(context=data, prediction_length=24)\n",
        "print(\"Predictions (Torch tensor):\\n\", type(quantiles), quantiles.shape)\n",
        "\n",
        "# List of Torch tensors (List of 1D) - will be padded\n",
        "list_torch_data = [data, data, data]\n",
        "quantiles, means = model.forecast(context=list_torch_data, prediction_length=24, batch_size=2)\n",
        "print(\"Predictions (List of Torch tensors):\\n\", type(quantiles), quantiles.shape)\n",
        "\n",
        "# NumPy array (2D or 1D)\n",
        "quantiles, means = model.forecast(context=data.numpy(), prediction_length=24, output_type=\"torch\")\n",
        "print(\"Predictions (NumPy):\\n\", type(quantiles), quantiles.shape)\n",
        "\n",
        "\n",
        "# List of NumPy arrays (List of 1D) - will be padded\n",
        "list_numpy_data = [data.numpy()]  # Split into 3 sequences\n",
        "quantiles, means = model.forecast(context=list_numpy_data, prediction_length=24)\n",
        "print(\"Predictions (List of NumPy arrays):\\n\", type(quantiles), quantiles.shape)\n",
        "\n",
        "\n",
        "# GluonTS Dataset\n",
        "try:\n",
        "    from typing import cast\n",
        "\n",
        "    from gluonts.dataset import Dataset\n",
        "\n",
        "    gluon_dataset = cast(Dataset, [{\"target\": data, \"item_id\": 1}, {\"target\": data, \"item_id\": 22}])\n",
        "    quantiles, means = model.forecast_gluon(gluon_dataset, prediction_length=24)\n",
        "    print(\"Predictions GluonDataset:\\n\", type(quantiles), quantiles.shape)\n",
        "    # If you use also `glutonts` as your output type the start_time and item_id get preserved accordingly\n",
        "    predictions_gluon = model.forecast_gluon(gluon_dataset, prediction_length=24, output_type=\"gluonts\")\n",
        "    print(\"Predictions GluonDataset:\\n\", type(predictions_gluon), type(predictions_gluon[0]))\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    # To use the gluonts function you need to install the optional dependency\n",
        "    # pip install tirex[gluonts]\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Output Options\n",
        "\n",
        "\n",
        "TiRex supports different output types for the forecasts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = torch.tensor(data_short)\n",
        "\n",
        "# Default: 2D Torch tensor\n",
        "quantiles, means = model.forecast(context=data, prediction_length=24, output_type=\"torch\")\n",
        "print(\"Predictions:\\n\", type(quantiles), quantiles.shape)\n",
        "\n",
        "\n",
        "# 2D Numpy Array\n",
        "quantiles, means = model.forecast(context=data, prediction_length=24, output_type=\"numpy\")\n",
        "print(\"Predictions:\\n\", type(quantiles), quantiles.shape)\n",
        "\n",
        "\n",
        "# Iterate by patch\n",
        "# You can also use the forecast function as iterable. This might help with big datasets. All output_types are supported\n",
        "for i, fc_batch in enumerate(\n",
        "    model.forecast(context=[data, data, data, data, data], batch_size=2, output_type=\"torch\", yield_per_batch=True)\n",
        "):\n",
        "    quantiles, means = fc_batch\n",
        "    print(f\"Predictions batch {i}:\\n\", type(quantiles), quantiles.shape)\n",
        "\n",
        "\n",
        "try:\n",
        "    # QuantileForecast (GluonTS)\n",
        "    predictions_gluonts = model.forecast(context=data, prediction_length=24, output_type=\"gluonts\")\n",
        "    print(\"Predictions (GluonTS Quantile Forecast):\\n\", type(predictions_gluon), type(predictions_gluon[0]))\n",
        "    predictions_gluonts[0].plot()\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    # To use the gluonts function you need to install the optional dependency\n",
        "    # pip install tirex[gluonts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
