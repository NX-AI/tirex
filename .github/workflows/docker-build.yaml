name: Build and Push Docker Images
on:
  workflow_run:
    workflows: ['Run Inference Tests']
    types: [completed]
    branches: [main]

jobs:
  build-and-push-docker-images:
    name: Build and Push Docker Images
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    if: ${{ github.event.workflow_run.conclusion == 'success' && github.repository == 'NX-AI/tirex' }}

    steps:
    - uses: actions/checkout@v5

    - name: Free up disk space
      run: |
        sudo rm -rf /opt/hostedtoolcache
        sudo rm -rf /usr/share/dotnet
        sudo rm -rf /usr/local/lib/android
        sudo rm -rf /opt/ghc
        sudo apt-get clean
        docker system prune -af --volumes

    - name: Extract version of TiRex from pyproject.toml
      id: get_version
      run: |
        VERSION=$(python3 -c "import tomllib; print(tomllib.load(open('pyproject.toml', 'rb'))['project']['version'])")
        echo "version=$VERSION" >> $GITHUB_OUTPUT

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Login to GitHub Container Registry
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Build and push CPU image
      uses: docker/build-push-action@v6
      with:
        platforms: linux/amd64,linux/arm64
        context: inference
        file: inference/Dockerfile.cpu
        tags: |
          ghcr.io/nx-ai/tirex-cpu:${{ steps.get_version.outputs.version }}
          ghcr.io/nx-ai/tirex-cpu:latest
        push: true
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Clean up after CPU build
      run: docker system prune -af --volumes

    - name: Build and push GPU image
      uses: docker/build-push-action@v6
      with:
        platforms: linux/amd64
        context: inference
        file: inference/Dockerfile.gpu
        tags: |
          ghcr.io/nx-ai/tirex-gpu:${{ steps.get_version.outputs.version }}
          ghcr.io/nx-ai/tirex-gpu:latest
        push: true
        cache-from: type=gha
        cache-to: type=gha,mode=max
